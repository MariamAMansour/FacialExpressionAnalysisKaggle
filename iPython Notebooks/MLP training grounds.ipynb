{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for Testing out the MLPs. The architecture written is the one with the best results for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0830 19:10:50.389726  1376 deprecation_wrapper.py:119] From C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:47: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0830 19:10:50.405717  1376 deprecation_wrapper.py:119] From C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:349: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0830 19:10:50.407677  1376 deprecation_wrapper.py:119] From C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3145: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0830 19:10:50.427659  1376 deprecation.py:506] From C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2681: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0830 19:10:50.473500  1376 deprecation_wrapper.py:119] From C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\keras\\optimizers.py:675: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0830 19:10:50.489493  1376 deprecation.py:506] From C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2548: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "W0830 19:10:50.496477  1376 deprecation_wrapper.py:119] From C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2552: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0830 19:10:51.033042  1376 deprecation.py:323] From C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0830 19:10:51.113821  1376 deprecation_wrapper.py:119] From C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:766: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "W0830 19:10:51.124794  1376 deprecation.py:506] From C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:519: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28709 samples, validate on 3589 samples\n",
      "Epoch 1/100\n",
      "Epoch 00000: val_acc improved from -inf to 0.29200, saving model to MLP.weights.best.hdf5\n",
      "5s - loss: 1.7827 - acc: 0.2739 - val_loss: 1.7362 - val_acc: 0.2920\n",
      "Epoch 2/100\n",
      "Epoch 00001: val_acc improved from 0.29200 to 0.33352, saving model to MLP.weights.best.hdf5\n",
      "3s - loss: 1.7144 - acc: 0.3193 - val_loss: 1.6771 - val_acc: 0.3335\n",
      "Epoch 3/100\n",
      "Epoch 00002: val_acc improved from 0.33352 to 0.37225, saving model to MLP.weights.best.hdf5\n",
      "3s - loss: 1.6811 - acc: 0.3349 - val_loss: 1.6409 - val_acc: 0.3722\n",
      "Epoch 4/100\n",
      "Epoch 00003: val_acc improved from 0.37225 to 0.37448, saving model to MLP.weights.best.hdf5\n",
      "3s - loss: 1.6593 - acc: 0.3448 - val_loss: 1.6415 - val_acc: 0.3745\n",
      "Epoch 5/100\n",
      "Epoch 00004: val_acc improved from 0.37448 to 0.38897, saving model to MLP.weights.best.hdf5\n",
      "3s - loss: 1.6495 - acc: 0.3529 - val_loss: 1.6120 - val_acc: 0.3890\n",
      "Epoch 6/100\n",
      "Epoch 00005: val_acc did not improve\n",
      "3s - loss: 1.6391 - acc: 0.3554 - val_loss: 1.6217 - val_acc: 0.3731\n",
      "Epoch 7/100\n",
      "Epoch 00006: val_acc did not improve\n",
      "3s - loss: 1.6234 - acc: 0.3627 - val_loss: 1.6084 - val_acc: 0.3745\n",
      "Epoch 8/100\n",
      "Epoch 00007: val_acc did not improve\n",
      "3s - loss: 1.6209 - acc: 0.3621 - val_loss: 1.6278 - val_acc: 0.3678\n",
      "Epoch 9/100\n",
      "Epoch 00008: val_acc did not improve\n",
      "3s - loss: 1.6129 - acc: 0.3675 - val_loss: 1.5996 - val_acc: 0.3801\n",
      "Epoch 10/100\n",
      "Epoch 00009: val_acc improved from 0.38897 to 0.39092, saving model to MLP.weights.best.hdf5\n",
      "3s - loss: 1.6036 - acc: 0.3705 - val_loss: 1.5841 - val_acc: 0.3909\n",
      "Epoch 11/100\n",
      "Epoch 00010: val_acc did not improve\n",
      "3s - loss: 1.5966 - acc: 0.3727 - val_loss: 1.6173 - val_acc: 0.3745\n",
      "Epoch 12/100\n",
      "Epoch 00011: val_acc did not improve\n",
      "3s - loss: 1.5869 - acc: 0.3759 - val_loss: 1.5780 - val_acc: 0.3828\n",
      "Epoch 13/100\n",
      "Epoch 00012: val_acc did not improve\n",
      "3s - loss: 1.5857 - acc: 0.3783 - val_loss: 1.5911 - val_acc: 0.3764\n",
      "Epoch 14/100\n",
      "Epoch 00013: val_acc did not improve\n",
      "3s - loss: 1.5729 - acc: 0.3869 - val_loss: 1.5969 - val_acc: 0.3689\n",
      "Epoch 15/100\n",
      "Epoch 00014: val_acc did not improve\n",
      "3s - loss: 1.5702 - acc: 0.3859 - val_loss: 1.5699 - val_acc: 0.3884\n",
      "Epoch 16/100\n",
      "Epoch 00015: val_acc did not improve\n",
      "3s - loss: 1.5599 - acc: 0.3897 - val_loss: 1.5846 - val_acc: 0.3742\n",
      "Epoch 17/100\n",
      "Epoch 00016: val_acc did not improve\n",
      "3s - loss: 1.5571 - acc: 0.3912 - val_loss: 1.5774 - val_acc: 0.3887\n",
      "Epoch 18/100\n",
      "Epoch 00017: val_acc did not improve\n",
      "3s - loss: 1.5505 - acc: 0.3964 - val_loss: 1.5690 - val_acc: 0.3892\n",
      "Epoch 19/100\n",
      "Epoch 00018: val_acc did not improve\n",
      "3s - loss: 1.5502 - acc: 0.3933 - val_loss: 1.5793 - val_acc: 0.3759\n",
      "Epoch 20/100\n",
      "Epoch 00019: val_acc improved from 0.39092 to 0.39983, saving model to MLP.weights.best.hdf5\n",
      "3s - loss: 1.5426 - acc: 0.3964 - val_loss: 1.5566 - val_acc: 0.3998\n",
      "Epoch 21/100\n",
      "Epoch 00020: val_acc did not improve\n",
      "3s - loss: 1.5380 - acc: 0.4003 - val_loss: 1.5636 - val_acc: 0.3831\n",
      "Epoch 22/100\n",
      "Epoch 00021: val_acc did not improve\n",
      "3s - loss: 1.5329 - acc: 0.4007 - val_loss: 1.5846 - val_acc: 0.3840\n",
      "Epoch 23/100\n",
      "Epoch 00022: val_acc did not improve\n",
      "3s - loss: 1.5329 - acc: 0.4010 - val_loss: 1.5765 - val_acc: 0.3859\n",
      "Epoch 24/100\n",
      "Epoch 00023: val_acc did not improve\n",
      "3s - loss: 1.5278 - acc: 0.4029 - val_loss: 1.5852 - val_acc: 0.3820\n",
      "Epoch 25/100\n",
      "Epoch 00024: val_acc did not improve\n",
      "3s - loss: 1.5270 - acc: 0.4030 - val_loss: 1.5623 - val_acc: 0.3862\n",
      "Epoch 26/100\n",
      "Epoch 00025: val_acc did not improve\n",
      "3s - loss: 1.5211 - acc: 0.4096 - val_loss: 1.5646 - val_acc: 0.3870\n",
      "Epoch 27/100\n",
      "Epoch 00026: val_acc did not improve\n",
      "3s - loss: 1.5242 - acc: 0.4041 - val_loss: 1.5544 - val_acc: 0.3915\n",
      "Epoch 28/100\n",
      "Epoch 00027: val_acc did not improve\n",
      "3s - loss: 1.5123 - acc: 0.4119 - val_loss: 1.5725 - val_acc: 0.3803\n",
      "Epoch 29/100\n",
      "Epoch 00028: val_acc did not improve\n",
      "3s - loss: 1.5073 - acc: 0.4154 - val_loss: 1.5567 - val_acc: 0.3937\n",
      "Epoch 30/100\n",
      "Epoch 00029: val_acc did not improve\n",
      "3s - loss: 1.5059 - acc: 0.4118 - val_loss: 1.5507 - val_acc: 0.3918\n",
      "Epoch 31/100\n",
      "Epoch 00030: val_acc did not improve\n",
      "3s - loss: 1.4983 - acc: 0.4174 - val_loss: 1.5768 - val_acc: 0.3845\n",
      "Epoch 32/100\n",
      "Epoch 00031: val_acc did not improve\n",
      "3s - loss: 1.4972 - acc: 0.4171 - val_loss: 1.5707 - val_acc: 0.3851\n",
      "Epoch 33/100\n",
      "Epoch 00032: val_acc did not improve\n",
      "3s - loss: 1.4959 - acc: 0.4207 - val_loss: 1.5501 - val_acc: 0.3856\n",
      "Epoch 34/100\n",
      "Epoch 00033: val_acc did not improve\n",
      "3s - loss: 1.4901 - acc: 0.4229 - val_loss: 1.5662 - val_acc: 0.3845\n",
      "Epoch 35/100\n",
      "Epoch 00034: val_acc did not improve\n",
      "3s - loss: 1.4898 - acc: 0.4246 - val_loss: 1.5633 - val_acc: 0.3909\n",
      "Epoch 36/100\n",
      "Epoch 00035: val_acc did not improve\n",
      "3s - loss: 1.4827 - acc: 0.4251 - val_loss: 1.5605 - val_acc: 0.3853\n",
      "Epoch 37/100\n",
      "Epoch 00036: val_acc did not improve\n",
      "3s - loss: 1.4763 - acc: 0.4274 - val_loss: 1.5348 - val_acc: 0.3982\n",
      "Epoch 38/100\n",
      "Epoch 00037: val_acc did not improve\n",
      "4s - loss: 1.4824 - acc: 0.4248 - val_loss: 1.5863 - val_acc: 0.3865\n",
      "Epoch 39/100\n",
      "Epoch 00038: val_acc did not improve\n",
      "5s - loss: 1.4714 - acc: 0.4289 - val_loss: 1.5873 - val_acc: 0.3831\n",
      "Epoch 40/100\n",
      "Epoch 00039: val_acc did not improve\n",
      "5s - loss: 1.4703 - acc: 0.4290 - val_loss: 1.5481 - val_acc: 0.3979\n",
      "Epoch 41/100\n",
      "Epoch 00040: val_acc did not improve\n",
      "5s - loss: 1.4656 - acc: 0.4302 - val_loss: 1.5614 - val_acc: 0.3957\n",
      "Epoch 42/100\n",
      "Epoch 00041: val_acc did not improve\n",
      "5s - loss: 1.4628 - acc: 0.4350 - val_loss: 1.5600 - val_acc: 0.3901\n",
      "Epoch 43/100\n",
      "Epoch 00042: val_acc did not improve\n",
      "5s - loss: 1.4653 - acc: 0.4322 - val_loss: 1.5622 - val_acc: 0.3943\n",
      "Epoch 44/100\n",
      "Epoch 00043: val_acc improved from 0.39983 to 0.40485, saving model to MLP.weights.best.hdf5\n",
      "5s - loss: 1.4550 - acc: 0.4381 - val_loss: 1.5384 - val_acc: 0.4048\n",
      "Epoch 45/100\n",
      "Epoch 00044: val_acc did not improve\n",
      "5s - loss: 1.4576 - acc: 0.4359 - val_loss: 1.5542 - val_acc: 0.3996\n",
      "Epoch 46/100\n",
      "Epoch 00045: val_acc did not improve\n",
      "6s - loss: 1.4495 - acc: 0.4382 - val_loss: 1.5816 - val_acc: 0.3848\n",
      "Epoch 47/100\n",
      "Epoch 00046: val_acc did not improve\n",
      "5s - loss: 1.4457 - acc: 0.4418 - val_loss: 1.5916 - val_acc: 0.3837\n",
      "Epoch 48/100\n",
      "Epoch 00047: val_acc did not improve\n",
      "5s - loss: 1.4468 - acc: 0.4387 - val_loss: 1.5690 - val_acc: 0.3918\n",
      "Epoch 49/100\n",
      "Epoch 00048: val_acc did not improve\n",
      "5s - loss: 1.4427 - acc: 0.4430 - val_loss: 1.5706 - val_acc: 0.3982\n",
      "Epoch 50/100\n",
      "Epoch 00049: val_acc did not improve\n",
      "5s - loss: 1.4392 - acc: 0.4467 - val_loss: 1.5600 - val_acc: 0.3998\n",
      "Epoch 51/100\n",
      "Epoch 00050: val_acc did not improve\n",
      "5s - loss: 1.4322 - acc: 0.4501 - val_loss: 1.5547 - val_acc: 0.3962\n",
      "Epoch 52/100\n",
      "Epoch 00051: val_acc did not improve\n",
      "5s - loss: 1.4321 - acc: 0.4460 - val_loss: 1.5790 - val_acc: 0.3940\n",
      "Epoch 53/100\n",
      "Epoch 00052: val_acc did not improve\n",
      "5s - loss: 1.4337 - acc: 0.4452 - val_loss: 1.5802 - val_acc: 0.4001\n",
      "Epoch 54/100\n",
      "Epoch 00053: val_acc did not improve\n",
      "5s - loss: 1.4353 - acc: 0.4473 - val_loss: 1.5811 - val_acc: 0.3951\n",
      "Epoch 55/100\n",
      "Epoch 00054: val_acc did not improve\n",
      "5s - loss: 1.4237 - acc: 0.4519 - val_loss: 1.5784 - val_acc: 0.3890\n",
      "Epoch 56/100\n",
      "Epoch 00055: val_acc did not improve\n",
      "5s - loss: 1.4261 - acc: 0.4511 - val_loss: 1.5601 - val_acc: 0.3959\n",
      "Epoch 57/100\n",
      "Epoch 00056: val_acc did not improve\n",
      "5s - loss: 1.4207 - acc: 0.4505 - val_loss: 1.5713 - val_acc: 0.3918\n",
      "Epoch 58/100\n",
      "Epoch 00057: val_acc did not improve\n",
      "5s - loss: 1.4183 - acc: 0.4535 - val_loss: 1.5670 - val_acc: 0.4040\n",
      "Epoch 59/100\n",
      "Epoch 00058: val_acc did not improve\n",
      "5s - loss: 1.4124 - acc: 0.4543 - val_loss: 1.5654 - val_acc: 0.4015\n",
      "Epoch 60/100\n",
      "Epoch 00059: val_acc did not improve\n",
      "5s - loss: 1.4112 - acc: 0.4563 - val_loss: 1.5800 - val_acc: 0.3940\n",
      "Epoch 61/100\n",
      "Epoch 00060: val_acc did not improve\n",
      "5s - loss: 1.4098 - acc: 0.4578 - val_loss: 1.5922 - val_acc: 0.3820\n",
      "Epoch 62/100\n",
      "Epoch 00061: val_acc did not improve\n",
      "5s - loss: 1.4109 - acc: 0.4554 - val_loss: 1.5812 - val_acc: 0.3920\n",
      "Epoch 63/100\n",
      "Epoch 00062: val_acc did not improve\n",
      "5s - loss: 1.3993 - acc: 0.4634 - val_loss: 1.5903 - val_acc: 0.3862\n",
      "Epoch 64/100\n",
      "Epoch 00063: val_acc did not improve\n",
      "5s - loss: 1.3972 - acc: 0.4602 - val_loss: 1.6024 - val_acc: 0.3876\n",
      "Epoch 65/100\n",
      "Epoch 00064: val_acc did not improve\n",
      "5s - loss: 1.4012 - acc: 0.4606 - val_loss: 1.5817 - val_acc: 0.4004\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00065: val_acc did not improve\n",
      "5s - loss: 1.3924 - acc: 0.4648 - val_loss: 1.5939 - val_acc: 0.3892\n",
      "Epoch 67/100\n",
      "Epoch 00066: val_acc did not improve\n",
      "5s - loss: 1.3933 - acc: 0.4652 - val_loss: 1.5915 - val_acc: 0.3934\n",
      "Epoch 68/100\n",
      "Epoch 00067: val_acc did not improve\n",
      "5s - loss: 1.3959 - acc: 0.4623 - val_loss: 1.6047 - val_acc: 0.3937\n",
      "Epoch 69/100\n",
      "Epoch 00068: val_acc did not improve\n",
      "5s - loss: 1.3931 - acc: 0.4656 - val_loss: 1.6034 - val_acc: 0.3940\n",
      "Epoch 70/100\n",
      "Epoch 00069: val_acc did not improve\n",
      "5s - loss: 1.3909 - acc: 0.4616 - val_loss: 1.5776 - val_acc: 0.3959\n",
      "Epoch 71/100\n",
      "Epoch 00070: val_acc did not improve\n",
      "5s - loss: 1.3860 - acc: 0.4698 - val_loss: 1.5773 - val_acc: 0.4032\n",
      "Epoch 72/100\n",
      "Epoch 00071: val_acc did not improve\n",
      "5s - loss: 1.3841 - acc: 0.4700 - val_loss: 1.5985 - val_acc: 0.4015\n",
      "Epoch 73/100\n",
      "Epoch 00072: val_acc did not improve\n",
      "5s - loss: 1.3847 - acc: 0.4686 - val_loss: 1.6106 - val_acc: 0.3915\n",
      "Epoch 74/100\n",
      "Epoch 00073: val_acc did not improve\n",
      "5s - loss: 1.3838 - acc: 0.4696 - val_loss: 1.6045 - val_acc: 0.3948\n",
      "Epoch 75/100\n",
      "Epoch 00074: val_acc did not improve\n",
      "5s - loss: 1.3808 - acc: 0.4701 - val_loss: 1.6060 - val_acc: 0.3906\n",
      "Epoch 76/100\n",
      "Epoch 00075: val_acc did not improve\n",
      "5s - loss: 1.3786 - acc: 0.4729 - val_loss: 1.6257 - val_acc: 0.3856\n",
      "Epoch 77/100\n",
      "Epoch 00076: val_acc did not improve\n",
      "5s - loss: 1.3757 - acc: 0.4717 - val_loss: 1.6029 - val_acc: 0.3937\n",
      "Epoch 78/100\n",
      "Epoch 00077: val_acc did not improve\n",
      "5s - loss: 1.3724 - acc: 0.4751 - val_loss: 1.5868 - val_acc: 0.3931\n",
      "Epoch 79/100\n",
      "Epoch 00078: val_acc did not improve\n",
      "5s - loss: 1.3698 - acc: 0.4738 - val_loss: 1.6039 - val_acc: 0.3812\n",
      "Epoch 80/100\n",
      "Epoch 00079: val_acc did not improve\n",
      "5s - loss: 1.3731 - acc: 0.4709 - val_loss: 1.6087 - val_acc: 0.3901\n",
      "Epoch 81/100\n",
      "Epoch 00080: val_acc did not improve\n",
      "5s - loss: 1.3751 - acc: 0.4725 - val_loss: 1.5974 - val_acc: 0.3998\n",
      "Epoch 82/100\n",
      "Epoch 00081: val_acc did not improve\n",
      "5s - loss: 1.3752 - acc: 0.4724 - val_loss: 1.6113 - val_acc: 0.3851\n",
      "Epoch 83/100\n",
      "Epoch 00082: val_acc did not improve\n",
      "5s - loss: 1.3692 - acc: 0.4755 - val_loss: 1.5902 - val_acc: 0.3951\n",
      "Epoch 84/100\n",
      "Epoch 00083: val_acc did not improve\n",
      "5s - loss: 1.3561 - acc: 0.4779 - val_loss: 1.6212 - val_acc: 0.3926\n",
      "Epoch 85/100\n",
      "Epoch 00084: val_acc did not improve\n",
      "5s - loss: 1.3604 - acc: 0.4798 - val_loss: 1.6340 - val_acc: 0.3909\n",
      "Epoch 86/100\n",
      "Epoch 00085: val_acc did not improve\n",
      "5s - loss: 1.3624 - acc: 0.4784 - val_loss: 1.6153 - val_acc: 0.3851\n",
      "Epoch 87/100\n",
      "Epoch 00086: val_acc did not improve\n",
      "5s - loss: 1.3560 - acc: 0.4799 - val_loss: 1.6271 - val_acc: 0.4007\n",
      "Epoch 88/100\n",
      "Epoch 00087: val_acc did not improve\n",
      "5s - loss: 1.3550 - acc: 0.4792 - val_loss: 1.6253 - val_acc: 0.3876\n",
      "Epoch 89/100\n",
      "Epoch 00088: val_acc did not improve\n",
      "5s - loss: 1.3516 - acc: 0.4806 - val_loss: 1.6180 - val_acc: 0.3962\n",
      "Epoch 90/100\n",
      "Epoch 00089: val_acc did not improve\n",
      "5s - loss: 1.3578 - acc: 0.4795 - val_loss: 1.6101 - val_acc: 0.3998\n",
      "Epoch 91/100\n",
      "Epoch 00090: val_acc did not improve\n",
      "5s - loss: 1.3436 - acc: 0.4870 - val_loss: 1.6263 - val_acc: 0.3973\n",
      "Epoch 92/100\n",
      "Epoch 00091: val_acc did not improve\n",
      "5s - loss: 1.3451 - acc: 0.4842 - val_loss: 1.6111 - val_acc: 0.3976\n",
      "Epoch 93/100\n",
      "Epoch 00092: val_acc did not improve\n",
      "5s - loss: 1.3455 - acc: 0.4856 - val_loss: 1.6264 - val_acc: 0.3909\n",
      "Epoch 94/100\n",
      "Epoch 00093: val_acc did not improve\n",
      "5s - loss: 1.3456 - acc: 0.4879 - val_loss: 1.6153 - val_acc: 0.3968\n",
      "Epoch 95/100\n",
      "Epoch 00094: val_acc did not improve\n",
      "5s - loss: 1.3402 - acc: 0.4894 - val_loss: 1.6506 - val_acc: 0.3937\n",
      "Epoch 96/100\n",
      "Epoch 00095: val_acc did not improve\n",
      "5s - loss: 1.3345 - acc: 0.4900 - val_loss: 1.6366 - val_acc: 0.3904\n",
      "Epoch 97/100\n",
      "Epoch 00096: val_acc did not improve\n",
      "5s - loss: 1.3414 - acc: 0.4883 - val_loss: 1.6238 - val_acc: 0.3937\n",
      "Epoch 98/100\n",
      "Epoch 00097: val_acc did not improve\n",
      "5s - loss: 1.3373 - acc: 0.4895 - val_loss: 1.6282 - val_acc: 0.3926\n",
      "Epoch 99/100\n",
      "Epoch 00098: val_acc did not improve\n",
      "5s - loss: 1.3360 - acc: 0.4869 - val_loss: 1.6158 - val_acc: 0.3887\n",
      "Epoch 100/100\n",
      "Epoch 00099: val_acc did not improve\n",
      "5s - loss: 1.3343 - acc: 0.4890 - val_loss: 1.6286 - val_acc: 0.4004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e2f5277ac8>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "#Loading Data\n",
    "data = pd.read_csv(\"fer2013.csv\")\n",
    "\n",
    "emotion = np.array(data['emotion'])\n",
    "pixels = np.array(data['pixels'])\n",
    "usage = np.array(data['Usage'])\n",
    "\n",
    "#Changing string to integer for the pixels\n",
    "for i in range(0, len(pixels)):\n",
    "    numbers = [int(x) for x in pixels[i].split(' ')]\n",
    "    pixels[i] = numbers\n",
    "\n",
    "#Scaling pixels from 0->255 to 0->1\n",
    "for i in range(0,len(pixels)):\n",
    "    for j in range(0, len(pixels[i])):\n",
    "        pixels[i][j] = pixels[i][j]/255\n",
    "\n",
    "#Splitting Data\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_valid = []\n",
    "y_valid = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for i in range(0, len(usage)):\n",
    "    if (usage[i] == \"Training\"):\n",
    "        x_train.append(pixels[i])\n",
    "        y_train.append(emotion[i])\n",
    "    elif (usage[i] == \"PublicTest\"):\n",
    "        x_valid.append(pixels[i])\n",
    "        y_valid.append(emotion[i])\n",
    "    elif (usage[i] == \"PrivateTest\"):\n",
    "        x_test.append(pixels[i])\n",
    "        y_test.append(emotion[i])\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_valid = np.array(x_valid)\n",
    "y_valid = np.array(y_valid)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "#One-hot Encoding\n",
    "y_train = np_utils.to_categorical(y_train, 7)\n",
    "y_valid = np_utils.to_categorical(y_valid, 7)\n",
    "y_test = np_utils.to_categorical(y_test, 7)\n",
    "\n",
    "#Model Architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(192, activation='relu',input_shape=x_train.shape[1:]))\n",
    "model.add(Dropout(0.05))\n",
    "model.add(Dense(96, activation='relu'))\n",
    "model.add(Dense(48, activation='relu'))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#model.summary() will show model summary\n",
    "\n",
    "#Training the Model\n",
    "checkpointer = ModelCheckpoint(filepath=\"MLP.weights.best.hdf5\", monitor='val_acc', verbose=1, save_best_only=True)\n",
    "model.fit(x_train, y_train, batch_size=60,\n",
    "          epochs=100, validation_data=(x_valid, y_valid),\n",
    "          callbacks = [checkpointer], verbose=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Best Model and Testing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy =  40.3176372256841\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(\"MLP.weights.best.hdf5\")\n",
    "testscore = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy = \", 100*testscore[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Capstone-Project",
   "language": "python",
   "name": "capstone-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
