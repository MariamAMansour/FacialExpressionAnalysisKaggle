{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0830 21:25:41.004240 15128 deprecation_wrapper.py:119] From C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:47: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0830 21:25:41.036652 15128 deprecation_wrapper.py:119] From C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:349: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0830 21:25:41.041312 15128 deprecation_wrapper.py:119] From C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3145: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0830 21:25:41.081902 15128 deprecation_wrapper.py:119] From C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3012: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0830 21:25:41.903849 15128 deprecation.py:506] From C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2681: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0830 21:25:41.984573 15128 deprecation_wrapper.py:119] From C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\keras\\optimizers.py:675: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0830 21:25:42.005925 15128 deprecation.py:506] From C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2548: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "W0830 21:25:42.013989 15128 deprecation_wrapper.py:119] From C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2552: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0830 21:25:42.371986 15128 deprecation.py:323] From C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0830 21:25:42.623337 15128 deprecation_wrapper.py:119] From C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:766: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "W0830 21:25:42.639219 15128 deprecation.py:506] From C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:519: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Epoch 00000: val_acc improved from -inf to 0.24937, saving model to CNN.weights.best.hdf5\n",
      "37s - loss: 1.8166 - acc: 0.2495 - val_loss: 1.7995 - val_acc: 0.2494\n",
      "Epoch 2/100\n",
      "Epoch 00001: val_acc improved from 0.24937 to 0.27473, saving model to CNN.weights.best.hdf5\n",
      "33s - loss: 1.7940 - acc: 0.2513 - val_loss: 1.7776 - val_acc: 0.2747\n",
      "Epoch 3/100\n",
      "Epoch 00002: val_acc did not improve\n",
      "36s - loss: 1.7734 - acc: 0.2620 - val_loss: 1.7643 - val_acc: 0.2661\n",
      "Epoch 4/100\n",
      "Epoch 00003: val_acc improved from 0.27473 to 0.33714, saving model to CNN.weights.best.hdf5\n",
      "37s - loss: 1.7274 - acc: 0.2965 - val_loss: 1.6509 - val_acc: 0.3371\n",
      "Epoch 5/100\n",
      "Epoch 00004: val_acc improved from 0.33714 to 0.40680, saving model to CNN.weights.best.hdf5\n",
      "62s - loss: 1.6091 - acc: 0.3572 - val_loss: 1.5329 - val_acc: 0.4068\n",
      "Epoch 6/100\n",
      "Epoch 00005: val_acc improved from 0.40680 to 0.45194, saving model to CNN.weights.best.hdf5\n",
      "44s - loss: 1.4945 - acc: 0.4190 - val_loss: 1.4249 - val_acc: 0.4519\n",
      "Epoch 7/100\n",
      "Epoch 00006: val_acc improved from 0.45194 to 0.46336, saving model to CNN.weights.best.hdf5\n",
      "53s - loss: 1.4194 - acc: 0.4518 - val_loss: 1.3944 - val_acc: 0.4634\n",
      "Epoch 8/100\n",
      "Epoch 00007: val_acc improved from 0.46336 to 0.47423, saving model to CNN.weights.best.hdf5\n",
      "96s - loss: 1.3625 - acc: 0.4730 - val_loss: 1.3574 - val_acc: 0.4742\n",
      "Epoch 9/100\n",
      "Epoch 00008: val_acc improved from 0.47423 to 0.49902, saving model to CNN.weights.best.hdf5\n",
      "82s - loss: 1.3104 - acc: 0.5002 - val_loss: 1.2768 - val_acc: 0.4990\n",
      "Epoch 10/100\n",
      "Epoch 00009: val_acc improved from 0.49902 to 0.51881, saving model to CNN.weights.best.hdf5\n",
      "61s - loss: 1.2692 - acc: 0.5137 - val_loss: 1.2475 - val_acc: 0.5188\n",
      "Epoch 11/100\n",
      "Epoch 00010: val_acc improved from 0.51881 to 0.52940, saving model to CNN.weights.best.hdf5\n",
      "58s - loss: 1.2364 - acc: 0.5272 - val_loss: 1.2204 - val_acc: 0.5294\n",
      "Epoch 12/100\n",
      "Epoch 00011: val_acc improved from 0.52940 to 0.53553, saving model to CNN.weights.best.hdf5\n",
      "59s - loss: 1.2068 - acc: 0.5403 - val_loss: 1.2088 - val_acc: 0.5355\n",
      "Epoch 13/100\n",
      "Epoch 00012: val_acc improved from 0.53553 to 0.54444, saving model to CNN.weights.best.hdf5\n",
      "84s - loss: 1.1794 - acc: 0.5496 - val_loss: 1.1974 - val_acc: 0.5444\n",
      "Epoch 14/100\n",
      "Epoch 00013: val_acc did not improve\n",
      "53s - loss: 1.1588 - acc: 0.5564 - val_loss: 1.1837 - val_acc: 0.5433\n",
      "Epoch 15/100\n",
      "Epoch 00014: val_acc improved from 0.54444 to 0.55280, saving model to CNN.weights.best.hdf5\n",
      "46s - loss: 1.1414 - acc: 0.5636 - val_loss: 1.1660 - val_acc: 0.5528\n",
      "Epoch 16/100\n",
      "Epoch 00015: val_acc improved from 0.55280 to 0.55391, saving model to CNN.weights.best.hdf5\n",
      "48s - loss: 1.1270 - acc: 0.5680 - val_loss: 1.1719 - val_acc: 0.5539\n",
      "Epoch 17/100\n",
      "Epoch 00016: val_acc improved from 0.55391 to 0.56980, saving model to CNN.weights.best.hdf5\n",
      "51s - loss: 1.1069 - acc: 0.5773 - val_loss: 1.1264 - val_acc: 0.5698\n",
      "Epoch 18/100\n",
      "Epoch 00017: val_acc improved from 0.56980 to 0.57035, saving model to CNN.weights.best.hdf5\n",
      "49s - loss: 1.0896 - acc: 0.5856 - val_loss: 1.1055 - val_acc: 0.5704\n",
      "Epoch 19/100\n",
      "Epoch 00018: val_acc did not improve\n",
      "48s - loss: 1.0848 - acc: 0.5865 - val_loss: 1.1389 - val_acc: 0.5662\n",
      "Epoch 20/100\n",
      "Epoch 00019: val_acc did not improve\n",
      "47s - loss: 1.0726 - acc: 0.5891 - val_loss: 1.1567 - val_acc: 0.5575\n",
      "Epoch 21/100\n",
      "Epoch 00020: val_acc improved from 0.57035 to 0.58094, saving model to CNN.weights.best.hdf5\n",
      "48s - loss: 1.0582 - acc: 0.5959 - val_loss: 1.1083 - val_acc: 0.5809\n",
      "Epoch 22/100\n",
      "Epoch 00021: val_acc improved from 0.58094 to 0.58540, saving model to CNN.weights.best.hdf5\n",
      "52s - loss: 1.0418 - acc: 0.6043 - val_loss: 1.0980 - val_acc: 0.5854\n",
      "Epoch 23/100\n",
      "Epoch 00022: val_acc improved from 0.58540 to 0.58596, saving model to CNN.weights.best.hdf5\n",
      "46s - loss: 1.0375 - acc: 0.6073 - val_loss: 1.1031 - val_acc: 0.5860\n",
      "Epoch 24/100\n",
      "Epoch 00023: val_acc did not improve\n",
      "43s - loss: 1.0275 - acc: 0.6077 - val_loss: 1.0946 - val_acc: 0.5818\n",
      "Epoch 25/100\n",
      "Epoch 00024: val_acc improved from 0.58596 to 0.58651, saving model to CNN.weights.best.hdf5\n",
      "44s - loss: 1.0221 - acc: 0.6133 - val_loss: 1.0743 - val_acc: 0.5865\n",
      "Epoch 26/100\n",
      "Epoch 00025: val_acc improved from 0.58651 to 0.59404, saving model to CNN.weights.best.hdf5\n",
      "443s - loss: 1.0161 - acc: 0.6139 - val_loss: 1.0726 - val_acc: 0.5940\n",
      "Epoch 27/100\n",
      "Epoch 00026: val_acc improved from 0.59404 to 0.59738, saving model to CNN.weights.best.hdf5\n",
      "26s - loss: 1.0055 - acc: 0.6192 - val_loss: 1.0709 - val_acc: 0.5974\n",
      "Epoch 28/100\n",
      "Epoch 00027: val_acc did not improve\n",
      "42s - loss: 0.9997 - acc: 0.6191 - val_loss: 1.0903 - val_acc: 0.5968\n",
      "Epoch 29/100\n",
      "Epoch 00028: val_acc did not improve\n",
      "141s - loss: 0.9911 - acc: 0.6237 - val_loss: 1.1027 - val_acc: 0.5815\n",
      "Epoch 30/100\n",
      "Epoch 00029: val_acc did not improve\n",
      "145s - loss: 0.9868 - acc: 0.6269 - val_loss: 1.0781 - val_acc: 0.5935\n",
      "Epoch 31/100\n",
      "Epoch 00030: val_acc improved from 0.59738 to 0.60100, saving model to CNN.weights.best.hdf5\n",
      "144s - loss: 0.9766 - acc: 0.6306 - val_loss: 1.0648 - val_acc: 0.6010\n",
      "Epoch 32/100\n",
      "Epoch 00031: val_acc improved from 0.60100 to 0.60351, saving model to CNN.weights.best.hdf5\n",
      "145s - loss: 0.9740 - acc: 0.6313 - val_loss: 1.0829 - val_acc: 0.6035\n",
      "Epoch 33/100\n",
      "Epoch 00032: val_acc improved from 0.60351 to 0.61159, saving model to CNN.weights.best.hdf5\n",
      "145s - loss: 0.9669 - acc: 0.6337 - val_loss: 1.0404 - val_acc: 0.6116\n",
      "Epoch 34/100\n",
      "Epoch 00033: val_acc did not improve\n",
      "145s - loss: 0.9599 - acc: 0.6348 - val_loss: 1.0549 - val_acc: 0.6085\n",
      "Epoch 35/100\n",
      "Epoch 00034: val_acc did not improve\n",
      "144s - loss: 0.9550 - acc: 0.6346 - val_loss: 1.0793 - val_acc: 0.5965\n",
      "Epoch 36/100\n",
      "Epoch 00035: val_acc did not improve\n",
      "144s - loss: 0.9480 - acc: 0.6421 - val_loss: 1.0451 - val_acc: 0.6113\n",
      "Epoch 37/100\n",
      "Epoch 00036: val_acc did not improve\n",
      "144s - loss: 0.9441 - acc: 0.6423 - val_loss: 1.0491 - val_acc: 0.6077\n",
      "Epoch 38/100\n",
      "Epoch 00037: val_acc did not improve\n",
      "144s - loss: 0.9442 - acc: 0.6446 - val_loss: 1.0410 - val_acc: 0.6091\n",
      "Epoch 39/100\n",
      "Epoch 00038: val_acc did not improve\n",
      "144s - loss: 0.9366 - acc: 0.6473 - val_loss: 1.0419 - val_acc: 0.6110\n",
      "Epoch 40/100\n",
      "Epoch 00039: val_acc did not improve\n",
      "145s - loss: 0.9273 - acc: 0.6466 - val_loss: 1.0492 - val_acc: 0.6094\n",
      "Epoch 41/100\n",
      "Epoch 00040: val_acc improved from 0.61159 to 0.61382, saving model to CNN.weights.best.hdf5\n",
      "145s - loss: 0.9273 - acc: 0.6486 - val_loss: 1.0522 - val_acc: 0.6138\n",
      "Epoch 42/100\n",
      "Epoch 00041: val_acc did not improve\n",
      "145s - loss: 0.9259 - acc: 0.6466 - val_loss: 1.0716 - val_acc: 0.5993\n",
      "Epoch 43/100\n",
      "Epoch 00042: val_acc did not improve\n",
      "145s - loss: 0.9218 - acc: 0.6526 - val_loss: 1.0415 - val_acc: 0.6063\n",
      "Epoch 44/100\n",
      "Epoch 00043: val_acc did not improve\n",
      "145s - loss: 0.9148 - acc: 0.6542 - val_loss: 1.0415 - val_acc: 0.6060\n",
      "Epoch 45/100\n",
      "Epoch 00044: val_acc improved from 0.61382 to 0.61577, saving model to CNN.weights.best.hdf5\n",
      "145s - loss: 0.9109 - acc: 0.6562 - val_loss: 1.0436 - val_acc: 0.6158\n",
      "Epoch 46/100\n",
      "Epoch 00045: val_acc improved from 0.61577 to 0.62301, saving model to CNN.weights.best.hdf5\n",
      "145s - loss: 0.9050 - acc: 0.6599 - val_loss: 1.0192 - val_acc: 0.6230\n",
      "Epoch 47/100\n",
      "Epoch 00046: val_acc did not improve\n",
      "145s - loss: 0.8966 - acc: 0.6616 - val_loss: 1.0232 - val_acc: 0.6113\n",
      "Epoch 48/100\n",
      "Epoch 00047: val_acc did not improve\n",
      "145s - loss: 0.8954 - acc: 0.6632 - val_loss: 1.0223 - val_acc: 0.6219\n",
      "Epoch 49/100\n",
      "Epoch 00048: val_acc did not improve\n",
      "145s - loss: 0.8894 - acc: 0.6659 - val_loss: 1.0566 - val_acc: 0.6180\n",
      "Epoch 50/100\n",
      "Epoch 00049: val_acc did not improve\n",
      "145s - loss: 0.8823 - acc: 0.6684 - val_loss: 1.0475 - val_acc: 0.6188\n",
      "Epoch 51/100\n",
      "Epoch 00050: val_acc did not improve\n",
      "145s - loss: 0.8829 - acc: 0.6656 - val_loss: 1.0721 - val_acc: 0.6052\n",
      "Epoch 52/100\n",
      "Epoch 00051: val_acc improved from 0.62301 to 0.62329, saving model to CNN.weights.best.hdf5\n",
      "145s - loss: 0.8818 - acc: 0.6687 - val_loss: 1.0462 - val_acc: 0.6233\n",
      "Epoch 53/100\n",
      "Epoch 00052: val_acc did not improve\n",
      "145s - loss: 0.8800 - acc: 0.6668 - val_loss: 1.0314 - val_acc: 0.6155\n",
      "Epoch 54/100\n",
      "Epoch 00053: val_acc did not improve\n",
      "145s - loss: 0.8737 - acc: 0.6671 - val_loss: 1.0415 - val_acc: 0.6127\n",
      "Epoch 55/100\n",
      "Epoch 00054: val_acc did not improve\n",
      "145s - loss: 0.8677 - acc: 0.6724 - val_loss: 1.0552 - val_acc: 0.6080\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00055: val_acc did not improve\n",
      "145s - loss: 0.8645 - acc: 0.6715 - val_loss: 1.0535 - val_acc: 0.6069\n",
      "Epoch 57/100\n",
      "Epoch 00056: val_acc did not improve\n",
      "145s - loss: 0.8606 - acc: 0.6744 - val_loss: 1.0914 - val_acc: 0.6041\n",
      "Epoch 58/100\n",
      "Epoch 00057: val_acc did not improve\n",
      "145s - loss: 0.8580 - acc: 0.6752 - val_loss: 1.0597 - val_acc: 0.6213\n",
      "Epoch 59/100\n",
      "Epoch 00058: val_acc did not improve\n",
      "145s - loss: 0.8483 - acc: 0.6806 - val_loss: 1.0369 - val_acc: 0.6180\n",
      "Epoch 60/100\n",
      "Epoch 00059: val_acc did not improve\n",
      "145s - loss: 0.8504 - acc: 0.6792 - val_loss: 1.0492 - val_acc: 0.6133\n",
      "Epoch 61/100\n",
      "Epoch 00060: val_acc did not improve\n",
      "145s - loss: 0.8433 - acc: 0.6803 - val_loss: 1.0396 - val_acc: 0.6199\n",
      "Epoch 62/100\n",
      "Epoch 00061: val_acc did not improve\n",
      "145s - loss: 0.8417 - acc: 0.6831 - val_loss: 1.0417 - val_acc: 0.6177\n",
      "Epoch 63/100\n",
      "Epoch 00062: val_acc did not improve\n",
      "145s - loss: 0.8384 - acc: 0.6825 - val_loss: 1.0461 - val_acc: 0.6227\n",
      "Epoch 64/100\n",
      "Epoch 00063: val_acc did not improve\n",
      "145s - loss: 0.8408 - acc: 0.6808 - val_loss: 1.0654 - val_acc: 0.6052\n",
      "Epoch 65/100\n",
      "Epoch 00064: val_acc did not improve\n",
      "145s - loss: 0.8311 - acc: 0.6870 - val_loss: 1.0621 - val_acc: 0.6163\n",
      "Epoch 66/100\n",
      "Epoch 00065: val_acc did not improve\n",
      "145s - loss: 0.8253 - acc: 0.6844 - val_loss: 1.0357 - val_acc: 0.6152\n",
      "Epoch 67/100\n",
      "Epoch 00066: val_acc improved from 0.62329 to 0.62636, saving model to CNN.weights.best.hdf5\n",
      "145s - loss: 0.8241 - acc: 0.6895 - val_loss: 1.0375 - val_acc: 0.6264\n",
      "Epoch 68/100\n",
      "Epoch 00067: val_acc did not improve\n",
      "145s - loss: 0.8298 - acc: 0.6869 - val_loss: 1.0489 - val_acc: 0.6219\n",
      "Epoch 69/100\n",
      "Epoch 00068: val_acc did not improve\n",
      "145s - loss: 0.8214 - acc: 0.6912 - val_loss: 1.0566 - val_acc: 0.6233\n",
      "Epoch 70/100\n",
      "Epoch 00069: val_acc did not improve\n",
      "145s - loss: 0.8169 - acc: 0.6893 - val_loss: 1.0729 - val_acc: 0.6194\n",
      "Epoch 71/100\n",
      "Epoch 00070: val_acc did not improve\n",
      "145s - loss: 0.8209 - acc: 0.6888 - val_loss: 1.0368 - val_acc: 0.6252\n",
      "Epoch 72/100\n",
      "Epoch 00071: val_acc did not improve\n",
      "145s - loss: 0.8109 - acc: 0.6927 - val_loss: 1.0534 - val_acc: 0.6250\n",
      "Epoch 73/100\n",
      "Epoch 00072: val_acc improved from 0.62636 to 0.62775, saving model to CNN.weights.best.hdf5\n",
      "145s - loss: 0.8024 - acc: 0.6956 - val_loss: 1.0261 - val_acc: 0.6278\n",
      "Epoch 74/100\n",
      "Epoch 00073: val_acc improved from 0.62775 to 0.63249, saving model to CNN.weights.best.hdf5\n",
      "145s - loss: 0.8038 - acc: 0.6941 - val_loss: 1.0609 - val_acc: 0.6325\n",
      "Epoch 75/100\n",
      "Epoch 00074: val_acc did not improve\n",
      "145s - loss: 0.8052 - acc: 0.6947 - val_loss: 1.0465 - val_acc: 0.6172\n",
      "Epoch 76/100\n",
      "Epoch 00075: val_acc did not improve\n",
      "145s - loss: 0.7977 - acc: 0.6981 - val_loss: 1.0334 - val_acc: 0.6280\n",
      "Epoch 77/100\n",
      "Epoch 00076: val_acc did not improve\n",
      "145s - loss: 0.8045 - acc: 0.6953 - val_loss: 1.0542 - val_acc: 0.6294\n",
      "Epoch 78/100\n",
      "Epoch 00077: val_acc did not improve\n",
      "145s - loss: 0.7977 - acc: 0.6992 - val_loss: 1.0501 - val_acc: 0.6255\n",
      "Epoch 79/100\n",
      "Epoch 00078: val_acc did not improve\n",
      "145s - loss: 0.7914 - acc: 0.7025 - val_loss: 1.0984 - val_acc: 0.6152\n",
      "Epoch 80/100\n",
      "Epoch 00079: val_acc did not improve\n",
      "145s - loss: 0.7914 - acc: 0.6986 - val_loss: 1.0950 - val_acc: 0.6166\n",
      "Epoch 81/100\n",
      "Epoch 00080: val_acc did not improve\n",
      "145s - loss: 0.7901 - acc: 0.7010 - val_loss: 1.0784 - val_acc: 0.6202\n",
      "Epoch 82/100\n",
      "Epoch 00081: val_acc did not improve\n",
      "145s - loss: 0.7854 - acc: 0.7044 - val_loss: 1.0665 - val_acc: 0.6247\n",
      "Epoch 83/100\n",
      "Epoch 00082: val_acc did not improve\n",
      "145s - loss: 0.7834 - acc: 0.7040 - val_loss: 1.0615 - val_acc: 0.6239\n",
      "Epoch 84/100\n",
      "Epoch 00083: val_acc did not improve\n",
      "145s - loss: 0.7771 - acc: 0.7080 - val_loss: 1.0530 - val_acc: 0.6319\n",
      "Epoch 85/100\n",
      "Epoch 00084: val_acc did not improve\n",
      "144s - loss: 0.7785 - acc: 0.7067 - val_loss: 1.0599 - val_acc: 0.6230\n",
      "Epoch 86/100\n",
      "Epoch 00085: val_acc did not improve\n",
      "145s - loss: 0.7808 - acc: 0.7037 - val_loss: 1.0850 - val_acc: 0.6236\n",
      "Epoch 87/100\n",
      "Epoch 00086: val_acc did not improve\n",
      "146s - loss: 0.7731 - acc: 0.7057 - val_loss: 1.0604 - val_acc: 0.6300\n",
      "Epoch 88/100\n",
      "Epoch 00087: val_acc did not improve\n",
      "147s - loss: 0.7788 - acc: 0.7030 - val_loss: 1.0581 - val_acc: 0.6308\n",
      "Epoch 89/100\n",
      "Epoch 00088: val_acc improved from 0.63249 to 0.63305, saving model to CNN.weights.best.hdf5\n",
      "146s - loss: 0.7569 - acc: 0.7121 - val_loss: 1.0746 - val_acc: 0.6330\n",
      "Epoch 90/100\n",
      "Epoch 00089: val_acc did not improve\n",
      "145s - loss: 0.7761 - acc: 0.7045 - val_loss: 1.0657 - val_acc: 0.6297\n",
      "Epoch 91/100\n",
      "Epoch 00090: val_acc did not improve\n",
      "145s - loss: 0.7597 - acc: 0.7127 - val_loss: 1.0922 - val_acc: 0.6325\n",
      "Epoch 92/100\n",
      "Epoch 00091: val_acc did not improve\n",
      "146s - loss: 0.7562 - acc: 0.7143 - val_loss: 1.0859 - val_acc: 0.6258\n",
      "Epoch 93/100\n",
      "Epoch 00092: val_acc did not improve\n",
      "145s - loss: 0.7618 - acc: 0.7114 - val_loss: 1.0847 - val_acc: 0.6317\n",
      "Epoch 94/100\n",
      "Epoch 00093: val_acc did not improve\n",
      "145s - loss: 0.7608 - acc: 0.7117 - val_loss: 1.0800 - val_acc: 0.6272\n",
      "Epoch 95/100\n",
      "Epoch 00094: val_acc did not improve\n",
      "145s - loss: 0.7560 - acc: 0.7136 - val_loss: 1.0624 - val_acc: 0.6172\n",
      "Epoch 96/100\n",
      "Epoch 00095: val_acc did not improve\n",
      "145s - loss: 0.7536 - acc: 0.7145 - val_loss: 1.0654 - val_acc: 0.6169\n",
      "Epoch 97/100\n",
      "Epoch 00096: val_acc did not improve\n",
      "145s - loss: 0.7497 - acc: 0.7145 - val_loss: 1.1069 - val_acc: 0.6308\n",
      "Epoch 98/100\n",
      "Epoch 00097: val_acc did not improve\n",
      "145s - loss: 0.7503 - acc: 0.7174 - val_loss: 1.0592 - val_acc: 0.6330\n",
      "Epoch 99/100\n",
      "Epoch 00098: val_acc did not improve\n",
      "145s - loss: 0.7440 - acc: 0.7181 - val_loss: 1.0950 - val_acc: 0.6266\n",
      "Epoch 100/100\n",
      "Epoch 00099: val_acc did not improve\n",
      "145s - loss: 0.7407 - acc: 0.7207 - val_loss: 1.0898 - val_acc: 0.6250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1802c87a7b8>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Flatten, Dense, Dropout, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "#Load the Data\n",
    "data = pd.read_csv(\"fer2013.csv\")\n",
    "\n",
    "emotion = np.array(data['emotion'])\n",
    "pixels = np.array(data['pixels'])\n",
    "usage = np.array(data['Usage'])\n",
    "\n",
    "#Changing string to integer for the pixels\n",
    "for i in range(0, len(pixels)):\n",
    "    numbers = [int(x) for x in pixels[i].split(' ')]\n",
    "    pixels[i] = numbers\n",
    "\n",
    "#Scaling pixels from 0->255 to 0->1\n",
    "for i in range(0,len(pixels)):\n",
    "    for j in range(0, len(pixels[i])):\n",
    "        pixels[i][j] = pixels[i][j]/255\n",
    "\n",
    "#Splitting Data\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_valid = []\n",
    "y_valid = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for i in range(0, len(usage)):\n",
    "    if (usage[i] == \"Training\"):\n",
    "        x_train.append(pixels[i])\n",
    "        y_train.append(emotion[i])\n",
    "    elif (usage[i] == \"PublicTest\"):\n",
    "        x_valid.append(pixels[i])\n",
    "        y_valid.append(emotion[i])\n",
    "    elif (usage[i] == \"PrivateTest\"):\n",
    "        x_test.append(pixels[i])\n",
    "        y_test.append(emotion[i])\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_valid = np.array(x_valid)\n",
    "y_valid = np.array(y_valid)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "#One-hot Encoding\n",
    "y_train = np_utils.to_categorical(y_train, 7)\n",
    "y_valid = np_utils.to_categorical(y_valid, 7)\n",
    "y_test = np_utils.to_categorical(y_test, 7)\n",
    "\n",
    "#unflatten pictures\n",
    "x_train_square = []\n",
    "x_valid_square = []\n",
    "x_test_square = []\n",
    "\n",
    "for i in range(len(x_train)):\n",
    "    x_train_square.append(x_train[i].reshape(48,48))\n",
    "\n",
    "for i in range(len(x_valid)):\n",
    "    x_valid_square.append(x_valid[i].reshape(48,48))\n",
    "    x_test_square.append(x_test[i].reshape(48,48))\n",
    "    \n",
    "x_train_square = np.array(x_train_square).reshape([-1,48,48,1])\n",
    "x_valid_square = np.array(x_valid_square).reshape([-1,48,48,1])\n",
    "x_test_square = np.array(x_test_square).reshape([-1,48,48,1])\n",
    "\n",
    "#Data Augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,    \n",
    "        horizontal_flip=True)\n",
    "        \n",
    "datagen.fit(x_train_square)\n",
    "\n",
    "#Model Architecture\n",
    "modelcnn = Sequential()\n",
    "modelcnn.add(Conv2D(32, kernel_size=2, strides=1, padding='same', activation='relu', input_shape=(48,48,1)))\n",
    "modelcnn.add(Conv2D(32, kernel_size=2, strides=1, padding='same', activation='relu'))\n",
    "modelcnn.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "modelcnn.add(Conv2D(64, kernel_size=2, strides=1, padding='same', activation='relu'))\n",
    "modelcnn.add(Conv2D(64, kernel_size=2, strides=1, padding='same', activation='relu'))\n",
    "modelcnn.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "modelcnn.add(Conv2D(128, kernel_size=2, strides=1, padding='same', activation='relu'))\n",
    "modelcnn.add(Conv2D(128, kernel_size=2, strides=1, padding='same', activation='relu'))\n",
    "modelcnn.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "modelcnn.add(Conv2D(286, kernel_size=2, strides=1, padding='same', activation='relu'))\n",
    "modelcnn.add(Conv2D(286, kernel_size=2, strides=1, padding='same', activation='relu'))\n",
    "modelcnn.add(GlobalAveragePooling2D())\n",
    "\n",
    "modelcnn.add(Dense(512, activation='relu'))\n",
    "modelcnn.add(Dropout(0.1))\n",
    "modelcnn.add(Dense(286, activation='relu'))\n",
    "modelcnn.add(Dropout(0.1))\n",
    "modelcnn.add(Dense(7, activation='softmax'))\n",
    "#modelcnn.summary() will show model summary\n",
    "\n",
    "#Training Model\n",
    "modelcnn.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "checkcnn = ModelCheckpoint(filepath=\"CNN.weights.best.hdf5\", monitor='val_acc', verbose=1, save_best_only=True)\n",
    "modelcnn.fit_generator(datagen.flow(x_train_square, y_train, batch_size=32),\n",
    "                   steps_per_epoch=x_train_square.shape[0]//32,\n",
    "                   epochs=100, verbose=2, callbacks=[checkcnn],\n",
    "                   validation_data=(x_valid_square, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Best Model and Testing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.19615492112592\n"
     ]
    }
   ],
   "source": [
    "modelcnn.load_weights(\"CNN.weights.best.hdf5\")\n",
    "testscore = modelcnn.evaluate(x_test_square, y_test, verbose=0)\n",
    "print(100*testscore[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Capstone-Project",
   "language": "python",
   "name": "capstone-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
