{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Data:\n",
    "data = pd.read_csv(\"fer2013.csv\")\n",
    "\n",
    "emotion = np.array(data['emotion'])\n",
    "pixels = np.array(data['pixels'])\n",
    "usage = np.array(data['Usage'])\n",
    "\n",
    "#Changing string to integer for the pixels\n",
    "for i in range(0, len(pixels)):\n",
    "    numbers = [int(x) for x in pixels[i].split(' ')]\n",
    "    pixels[i] = numbers\n",
    "\n",
    "#Scaling pixels from 0->255 to 0->1\n",
    "for i in range(0,len(pixels)):\n",
    "    for j in range(0, len(pixels[i])):\n",
    "        pixels[i][j] = pixels[i][j]/255\n",
    "\n",
    "#Splitting Data\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_valid = []\n",
    "y_valid = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for i in range(0, len(usage)):\n",
    "    if (usage[i] == \"Training\"):\n",
    "        x_train.append(pixels[i])\n",
    "        y_train.append(emotion[i])\n",
    "    elif (usage[i] == \"PublicTest\"):\n",
    "        x_valid.append(pixels[i])\n",
    "        y_valid.append(emotion[i])\n",
    "    elif (usage[i] == \"PrivateTest\"):\n",
    "        x_test.append(pixels[i])\n",
    "        y_test.append(emotion[i])\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_valid = np.array(x_valid)\n",
    "y_valid = np.array(y_valid)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "#Unfalttened pictures\n",
    "x_train_square = []\n",
    "x_valid_square = []\n",
    "x_test_square = []\n",
    "\n",
    "for i in range(len(x_train)):\n",
    "    x_train_square.append(x_train[i].reshape(48,48))\n",
    "\n",
    "for i in range(len(x_valid)):\n",
    "    x_valid_square.append(x_valid[i].reshape(48,48))\n",
    "    x_test_square.append(x_test[i].reshape(48,48))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Images from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14886f3bfd0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 10 #insert any index you want to visualize\n",
    "#in the following line: (x_train_square) can be changed to (x_valid_square) or (x_test_square)\n",
    "arr = np.asarray(x_train_square[index])\n",
    "plt.imshow(arr, cmap='gray', vmin=0, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Information from Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Pictures =  35887\n",
      "Total Number of Pictures for Training =  28709\n",
      "Total Number of Pictures for Validation =  3589\n",
      "Total Number of Pictures for Testing =  3589\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Number of Pictures = \", len(pixels))\n",
    "print(\"Total Number of Pictures for Training = \", len(x_train))\n",
    "print(\"Total Number of Pictures for Validation = \", len(x_valid))\n",
    "print(\"Total Number of Pictures for Testing = \", len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics for each Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counting(find, array):\n",
    "    #Counts the number of occurrences of (find) in (array)\n",
    "    count = 0\n",
    "    \n",
    "    for i in array:\n",
    "        if i==find:\n",
    "            count=count+1\n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of each emotion in the Set: \n",
      "Anger:  4953\n",
      "Disgust:  547\n",
      "Fear:  5121\n",
      "Happiness:  8989\n",
      "Sadness:  6077\n",
      "Surprise:  4002\n",
      "Neutral:  6198\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Number of each emotion in the Set: \")\n",
    "#replace (emotion) in the following lines with (y_train)/(y_valid)/(y_test)\n",
    "#for training/validation/testing sets respectively\n",
    "print(\"Anger: \", counting(0,emotion))\n",
    "print(\"Disgust: \", counting(1,emotion))\n",
    "print(\"Fear: \", counting(2,emotion))\n",
    "print(\"Happiness: \", counting(3,emotion))\n",
    "print(\"Sadness: \", counting(4,emotion))\n",
    "print(\"Surprise: \", counting(5,emotion))\n",
    "print(\"Neutral: \", counting(6,emotion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To test accuracies of saved best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexing(find,array):\n",
    "#Returns an array of indexes for (find) in (array)\n",
    "    indexes=[]\n",
    "    \n",
    "    for i in range(len(array)):\n",
    "        if array[i]==find:\n",
    "            indexes.append(i)\n",
    "    \n",
    "    return indexes\n",
    "\n",
    "def filtering(indexes, array):\n",
    "#returns a new array with only the indexes in (indexes)\n",
    "    new_array=[]\n",
    "    \n",
    "    for i in indexes:\n",
    "        new_array.append(array[i])\n",
    "        \n",
    "    return new_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0831 01:34:58.201165  1952 deprecation_wrapper.py:119] From C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:47: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0831 01:34:58.225323  1952 deprecation_wrapper.py:119] From C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:349: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0831 01:34:58.229872  1952 deprecation_wrapper.py:119] From C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3145: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0831 01:34:58.262733  1952 deprecation.py:506] From C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2681: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0831 01:34:58.402722  1952 deprecation_wrapper.py:119] From C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:140: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0831 01:34:58.402722  1952 deprecation_wrapper.py:119] From C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:145: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0831 01:35:00.383110  1952 deprecation_wrapper.py:119] From C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\keras\\optimizers.py:675: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0831 01:35:00.421248  1952 deprecation.py:506] From C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2548: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "#one-hot encoding the labels\n",
    "y_train_encoded = np_utils.to_categorical(y_train, 7)\n",
    "y_valid_encoded = np_utils.to_categorical(y_valid, 7)\n",
    "y_test_encoded = np_utils.to_categorical(y_test, 7)\n",
    "\n",
    "#Setting up architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(192, activation='relu',input_shape=x_train.shape[1:]))\n",
    "model.add(Dropout(0.05))\n",
    "model.add(Dense(96, activation='relu'))\n",
    "model.add(Dense(48, activation='relu'))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "#Loading weights of saved model and compiling\n",
    "model.load_weights(\"MLP.weights.best.hdf5\")\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set Accuracy =  40.3176372256841\n"
     ]
    }
   ],
   "source": [
    "#(x_test) and (y_test_encoded) can be changed to any of the other sets\n",
    "#(x_train, y_train_encoded)/(x_valid, y_valid_encoded)\n",
    "set_score = model.evaluate(x_test, y_test_encoded, verbose=0)\n",
    "print(\"Set Accuracy = \", 100*set_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion Accuracy =  23.45431790408563\n"
     ]
    }
   ],
   "source": [
    "#To test accuracy for specific emotion\n",
    "#Anger: 0; Disgust: 1; Fear: 2; Happiness: 3; Sadness: 4; Surprise: 5; Neutral:6\n",
    "\n",
    "emotion=0\n",
    "indexes=indexing(emotion,y_train)\n",
    "x_emotion=np.array(filtering(indexes, x_train))\n",
    "y_emotion=np.array(filtering(indexes, y_train_encoded))\n",
    "\n",
    "emotion_score = model.evaluate(x_emotion, y_emotion, verbose=0)\n",
    "print(\"Emotion Accuracy = \", 100*emotion_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0831 01:35:02.490355  1952 deprecation_wrapper.py:119] From C:\\Users\\shrfm\\.conda\\envs\\capstone-project\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3012: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Adjusting Input array sizes for convolutional network\n",
    "x_train_square_input = np.array(x_train_square).reshape([-1,48,48,1])\n",
    "x_valid_square_input = np.array(x_valid_square).reshape([-1,48,48,1])\n",
    "x_test_square_input = np.array(x_test_square).reshape([-1,48,48,1])\n",
    "\n",
    "#Setting up Architecture\n",
    "modelcnn = Sequential()\n",
    "modelcnn.add(Conv2D(32, kernel_size=2, strides=1, padding='same', activation='relu', input_shape=(48,48,1)))\n",
    "modelcnn.add(Conv2D(32, kernel_size=2, strides=1, padding='same', activation='relu'))\n",
    "modelcnn.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "modelcnn.add(Conv2D(64, kernel_size=2, strides=1, padding='same', activation='relu'))\n",
    "modelcnn.add(Conv2D(64, kernel_size=2, strides=1, padding='same', activation='relu'))\n",
    "modelcnn.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "modelcnn.add(Conv2D(128, kernel_size=2, strides=1, padding='same', activation='relu'))\n",
    "modelcnn.add(Conv2D(128, kernel_size=2, strides=1, padding='same', activation='relu'))\n",
    "modelcnn.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "modelcnn.add(Conv2D(286, kernel_size=2, strides=1, padding='same', activation='relu'))\n",
    "modelcnn.add(Conv2D(286, kernel_size=2, strides=1, padding='same', activation='relu'))\n",
    "modelcnn.add(GlobalAveragePooling2D())\n",
    "\n",
    "modelcnn.add(Dense(512, activation='relu'))\n",
    "modelcnn.add(Dropout(0.1))\n",
    "modelcnn.add(Dense(286, activation='relu'))\n",
    "modelcnn.add(Dropout(0.1))\n",
    "modelcnn.add(Dense(7, activation='softmax'))\n",
    "\n",
    "#Loading the best saved model and compiling\n",
    "modelcnn.load_weights(\"CNN.weights.best.hdf5\")\n",
    "modelcnn.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set Accuracy =  64.19615492112592\n"
     ]
    }
   ],
   "source": [
    "#(x_test) and (y_test_encoded) can be changed to any of the other sets\n",
    "#(x_train, y_train_encoded)/(x_valid, y_valid_encoded)\n",
    "set_score = modelcnn.evaluate(x_test_square_input, y_test_encoded, verbose=0)\n",
    "print(\"Set Accuracy = \", 100*set_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion Accuracy =  64.33041302522223\n"
     ]
    }
   ],
   "source": [
    "#To test accuracy for specific emotion\n",
    "#Anger: 0; Disgust: 1; Fear: 2; Happiness: 3; Sadness: 4; Surprise: 5; Neutral:6\n",
    "\n",
    "emotion=0\n",
    "indexes=indexing(emotion,y_train)\n",
    "x_emotion=np.array(filtering(indexes, x_train_square_input))\n",
    "y_emotion=np.array(filtering(indexes, y_train_encoded))\n",
    "\n",
    "emotion_score = modelcnn.evaluate(x_emotion, y_emotion, verbose=0)\n",
    "print(\"Emotion Accuracy = \", 100*emotion_score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Capstone-Project",
   "language": "python",
   "name": "capstone-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
